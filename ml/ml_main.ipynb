{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import choice, sample\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.layers import Input, Dense, GlobalMaxPool2D, GlobalAvgPool2D, Concatenate, Multiply, Dropout, Subtract\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras_vggface.utils import preprocess_input\n",
    "from keras_vggface.vggface import VGGFace \n",
    "import cv2\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of Training Images: 15845\n",
      "Sample Path of each Training Image: TSKinFace\\train-faces\\train-faces\\F0001\\MID1\\P00001_face0.jpg\n",
      "\n",
      "Number of Families: 1209\n",
      "\n",
      "Sample 1 of Family Tuple: ('F0002/MID1', 'F0002/MID2', 'F0002/MID3')\n",
      "Sample 1 Label of Training Triplet Tuple: 1\n",
      "\n",
      "Number of people in Trianing Data: 3020\n",
      "Sample of mapping each person to their images: ('F0001/MID1', ['TSKinFace\\\\train-faces\\\\train-faces\\\\F0001\\\\MID1\\\\P00001_face0.jpg', 'TSKinFace\\\\train-faces\\\\train-faces\\\\F0001\\\\MID1\\\\P00002_face0.jpg', 'TSKinFace\\\\train-faces\\\\train-faces\\\\F0001\\\\MID1\\\\P00003_face0.jpg', 'TSKinFace\\\\train-faces\\\\train-faces\\\\F0001\\\\MID1\\\\P00004_face1.jpg', 'TSKinFace\\\\train-faces\\\\train-faces\\\\F0001\\\\MID1\\\\P00007_face1.jpg', 'TSKinFace\\\\train-faces\\\\train-faces\\\\F0001\\\\MID1\\\\P00008_face4.jpg'])\n"
     ]
    }
   ],
   "source": [
    "train_triplets = pd.read_csv('TSKinFace/train_triplets.csv')\n",
    "\n",
    "\n",
    "Fathers_train = train_triplets.F.values     # No. of fathers\n",
    "Mothers_train = train_triplets.M.values     # No. of mothers\n",
    "Children_train = train_triplets.C.values    # No. of children\n",
    "\n",
    "train_folders_path = \"TSKinFace\\\\train-faces\\\\train-faces\\\\\"\n",
    "all_train_images = glob(train_folders_path + \"*/MID*/*.jpg\")\n",
    "\n",
    "print(\"\\nNumber of Training Images:\", len(all_train_images))\n",
    "print(\"Sample Path of each Training Image:\", all_train_images[0])\n",
    "\n",
    "ppl = [x.split(\"\\\\\")[-3] + \"/\" + x.split(\"\\\\\")[-2] for x in all_train_images]\n",
    "\n",
    "ppl = (set(ppl))\n",
    "\n",
    "\n",
    "triplet_family_comb = list(zip(train_triplets.F.values, train_triplets.M.values, train_triplets.C.values))\n",
    "triplet_family_comb = [x for x in triplet_family_comb if x[0] in ppl and x[1] in ppl and x[2] in ppl]\n",
    "\n",
    "Fathers_train = [x for x in Fathers_train if x in ppl]\n",
    "Mothers_train = [x for x in Mothers_train if x in ppl]\n",
    "Children_train = [x for x in Children_train if x in ppl]\n",
    "\n",
    "print(\"\\nNumber of Families:\", len(triplet_family_comb))\n",
    "training_labels = [1]*len(triplet_family_comb)\n",
    "\n",
    "print(\"\\nSample 1 of Family Tuple:\", triplet_family_comb[0])\n",
    "print(\"Sample 1 Label of Training Triplet Tuple:\", training_labels[0])\n",
    "\n",
    "map_train_individual_to_images = defaultdict(list)\n",
    "\n",
    "for x in all_train_images:\n",
    "    map_train_individual_to_images[x.split(\n",
    "        \"\\\\\")[-3] + \"/\" + x.split(\"\\\\\")[-2]].append(x)\n",
    "\n",
    "print(\"\\nNumber of people in Trianing Data:\",\n",
    "    len(map_train_individual_to_images.keys()))\n",
    "print(\"Sample of mapping each person to their images:\",\n",
    "    list(map_train_individual_to_images.items())[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of validation Images: 5045\n",
      "Sample Path of each validation Image: TSKinFace\\val-faces\\val-faces\\F0007\\MID1\\P00073_face2.jpg\n",
      "\n",
      "Number of validation Pairs: 3568\n",
      "\n",
      "Sample 1 of validation Triplet Tuple: ('F0290/MID5/P03086_face7.jpg', 'F0290/MID1/P03087_face0.jpg', 'F0652/MID1/P03819_face3.jpg')\n",
      "Sample 1 Label of validation Triplet Tuple: 0\n",
      "\n",
      "Sample 2 of validation Triplet Tuple: ('F0879/MID2/P09279_face0.jpg', 'F0879/MID1/P09279_face3.jpg', 'F0879/MID5/P09276_face4.jpg')\n",
      "Sample 2 Label of validation Triplet Tuple: 1\n",
      "\n",
      "Number of people in validation Data: 966\n",
      "Sample of mapping each person to their images: ('F0007\\\\MID1', ['TSKinFace\\\\val-faces\\\\val-faces\\\\F0007\\\\MID1\\\\P00073_face2.jpg', 'TSKinFace\\\\val-faces\\\\val-faces\\\\F0007\\\\MID1\\\\P00074_face3.jpg', 'TSKinFace\\\\val-faces\\\\val-faces\\\\F0007\\\\MID1\\\\P00075_face0.jpg', 'TSKinFace\\\\val-faces\\\\val-faces\\\\F0007\\\\MID1\\\\P00076_face5.jpg', 'TSKinFace\\\\val-faces\\\\val-faces\\\\F0007\\\\MID1\\\\P00077_face12.jpg', 'TSKinFace\\\\val-faces\\\\val-faces\\\\F0007\\\\MID1\\\\P00078_face3.jpg', 'TSKinFace\\\\val-faces\\\\val-faces\\\\F0007\\\\MID1\\\\P00079_face1.jpg', 'TSKinFace\\\\val-faces\\\\val-faces\\\\F0007\\\\MID1\\\\P00080_face2.jpg', 'TSKinFace\\\\val-faces\\\\val-faces\\\\F0007\\\\MID1\\\\P00081_face0.jpg', 'TSKinFace\\\\val-faces\\\\val-faces\\\\F0007\\\\MID1\\\\P00082_face1.jpg', 'TSKinFace\\\\val-faces\\\\val-faces\\\\F0007\\\\MID1\\\\P11274_face3.jpg', 'TSKinFace\\\\val-faces\\\\val-faces\\\\F0007\\\\MID1\\\\P11275_face2.jpg', 'TSKinFace\\\\val-faces\\\\val-faces\\\\F0007\\\\MID1\\\\P11276_face1.jpg', 'TSKinFace\\\\val-faces\\\\val-faces\\\\F0007\\\\MID1\\\\P11277_face5.jpg'])\n"
     ]
    }
   ],
   "source": [
    "val_triplets = pd.read_csv('TSKinFace/val_triples_competition_with_label.csv')\n",
    "\n",
    "\n",
    "Fathers_val = val_triplets.F.values\n",
    "Mothers_val = val_triplets.M.values\n",
    "Children_val = val_triplets.C.values\n",
    "\n",
    "val_folders_path = \"TSKinFace\\\\val-faces\\\\val-faces\\\\\"\n",
    "all_val_images = glob(val_folders_path + \"*/MID*/*.jpg\")\n",
    "\n",
    "print(\"\\nNumber of validation Images:\", len(all_val_images))\n",
    "print(\"Sample Path of each validation Image:\", all_val_images[0])\n",
    "\n",
    "ppl = [x.split(\"\\\\\")[-3] + \"/\" + x.split(\"\\\\\")[-2] + \"/\" + x.split(\"\\\\\")[-1] for x in all_val_images]\n",
    "\n",
    "Fathers_val = [x for x in Fathers_val if x in ppl]\n",
    "Mothers_val = [x for x in Mothers_val if x in ppl]\n",
    "Children_val = [x for x in Children_val if x in ppl]\n",
    "\n",
    "triplet_val = list(\n",
    "    zip(val_triplets.F.values, val_triplets.M.values, val_triplets.C.values))\n",
    "triplet_val = [x for x in triplet_val if x[0] in ppl and x[1] in ppl and x[2] in ppl]\n",
    "\n",
    "print(\"\\nNumber of validation Pairs:\", len(triplet_val))\n",
    "\n",
    "validation_labels = list(val_triplets.label.values)\n",
    "validation_labels = [int(x) for x in validation_labels]\n",
    "\n",
    "print(\"\\nSample 1 of validation Triplet Tuple:\", triplet_val[0])\n",
    "print(\"Sample 1 Label of validation Triplet Tuple:\", validation_labels[0])\n",
    "\n",
    "print(\"\\nSample 2 of validation Triplet Tuple:\", triplet_val[1])\n",
    "print(\"Sample 2 Label of validation Triplet Tuple:\", validation_labels[1])\n",
    "\n",
    "map_val_individual_to_images = defaultdict(list)\n",
    "\n",
    "for x in all_val_images:\n",
    "    map_val_individual_to_images[x.split(\"\\\\\")[-3] + \"\\\\\" + x.split(\"\\\\\")[-2]].append(x)\n",
    "\n",
    "print(\"\\nNumber of people in validation Data:\", len(map_val_individual_to_images.keys()))\n",
    "print(\"Sample of mapping each person to their images:\", list(map_val_individual_to_images.items())[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_img(path):\n",
    "    # print('\\n',8)\n",
    "    img = cv2.imread(path)\n",
    "    img = cv2.resize(img, (224, 224), interpolation = cv2.INTER_LINEAR)\n",
    "\n",
    "    # print('\\n',9)\n",
    "    img = np.array(img, dtype=object).astype(np.float64)\n",
    "    # print('\\n',10)\n",
    "    return preprocess_input(img, version=2)\n",
    "\n",
    "\n",
    "def gen(list_tuples, person_to_images_map, F, M, C, batch_size=16):\n",
    "    # print('\\n',1)\n",
    "    while True:\n",
    "        batch_tuples = sample(list_tuples, batch_size // 2)\n",
    "        labels = [1] * len(batch_tuples)  # postive samples\n",
    "        while len(batch_tuples) < batch_size:\n",
    "            p1 = choice(F)\n",
    "            p2 = choice(M)\n",
    "            p3 = choice(C)\n",
    "\n",
    "            if (p1, p2, p3) not in list_tuples and p1 != p2  and p2 != p3 and p1 != p3:\n",
    "                batch_tuples.append((p1, p2, p3))\n",
    "                labels.append(0)  # negative samples\n",
    "        # print('\\n', batch_tuples)\n",
    "        X1 = [choice(person_to_images_map[x[0]]) for x in batch_tuples]\n",
    "        X1 = [read_img(x) for x in X1]\n",
    "        # shapeX1 = [x.shape for x in X1]\n",
    "        # print(shapeX1, len(shapeX1))\n",
    "        X1 = np.array(X1)\n",
    "        # print('\\n',2)\n",
    "\n",
    "        X2 = [choice(person_to_images_map[x[1]]) for x in batch_tuples]\n",
    "        X2 = [read_img(x) for x in X2]\n",
    "        # shapeX2 = [x.shape for x in X2]\n",
    "        # print(shapeX2, len(shapeX2))\n",
    "        X2 = np.array(X2)\n",
    "        # print('\\n',3)\n",
    "\n",
    "        X3 = [choice(person_to_images_map[x[2]]) for x in batch_tuples]\n",
    "        X3 = [read_img(x) for x in X3]\n",
    "        # shapeX3 = [x.shape for x in X3]\n",
    "        # print(shapeX3, len(shapeX3))\n",
    "        X3 = np.array(X3)\n",
    "        # print('\\n',4)\n",
    "        labels = np.asarray(labels).astype('float32').reshape((-1, 1))\n",
    "        # print('\\n',5)\n",
    "        yield [X1, X2, X3], labels\n",
    "\n",
    "\n",
    "def gen_val(triplet_val, validation_labels, batch_size=16):\n",
    "    while True:\n",
    "        val = list(zip(triplet_val, validation_labels))\n",
    "        val0 = [x for x in val if x[1] == 0]\n",
    "        val1 = [x for x in val if x[1] == 1]\n",
    "        batch_tuples0 = sample(val0, batch_size//2)\n",
    "        batch_tuples1 = sample(val1, batch_size//2)\n",
    "        batch_tuples = batch_tuples0 + batch_tuples1\n",
    "        # print(batch_tuples)\n",
    "        X1 = [read_img(val_folders_path + x[0][0]) for x in batch_tuples]\n",
    "        X1 = np.array(X1)\n",
    "        X2 = [read_img(val_folders_path + x[0][1]) for x in batch_tuples]\n",
    "        X2 = np.array(X2)\n",
    "        X3 = [read_img(val_folders_path + x[0][2]) for x in batch_tuples]\n",
    "        X3 = np.array(X3)\n",
    "        labels = [0]*(batch_size//2) + [1]*(batch_size//2)\n",
    "        labels = np.asarray(labels).astype('float32').reshape((-1, 1))\n",
    "        # print(labels)\n",
    "        yield [X1, X2, X3], labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "\n",
    "def baseline_model():\n",
    "    # print('\\n',7)\n",
    "    input_1 = Input(shape=(224, 224, 3))\n",
    "    input_2 = Input(shape=(224, 224, 3))\n",
    "    input_3 = Input(shape=(224, 224, 3))\n",
    "\n",
    "    base_model = VGGFace(model='resnet50', include_top=False)\n",
    "\n",
    "    for x in base_model.layers[:-3]:\n",
    "        x.trainable = True\n",
    "\n",
    "    x1 = base_model(input_1)\n",
    "    x2 = base_model(input_2)\n",
    "    x3 = base_model(input_3)\n",
    "\n",
    "    x1 = Concatenate(axis=-1)([GlobalMaxPool2D()(x1), GlobalAvgPool2D()(x1)])\n",
    "    x2 = Concatenate(axis=-1)([GlobalMaxPool2D()(x2), GlobalAvgPool2D()(x2)])\n",
    "    x3 = Concatenate(axis=-1)([GlobalMaxPool2D()(x3), GlobalAvgPool2D()(x3)])\n",
    "\n",
    "    x4 = Subtract()([x1, x3])\n",
    "    x4 = Multiply()([x4, x4])\n",
    "\n",
    "    x5 = Subtract()([x2, x3])\n",
    "    x5 = Multiply()([x5, x5])\n",
    "\n",
    "    x13 = Multiply()([x1, x3])\n",
    "    x13 = Concatenate(axis=-1)([x13, x4])\n",
    "\n",
    "    x23 = Multiply()([x2, x3])\n",
    "    x23 = Concatenate(axis=-1)([x23, x5])\n",
    "\n",
    "    x = Concatenate(axis=-1)([x13, x23])\n",
    "\n",
    "    x = Dense(100, activation=\"relu\")(x)\n",
    "    x = Dropout(0.01)(x)\n",
    "    out = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = Model([input_1, input_2, input_3], out)\n",
    "\n",
    "    model.compile(loss=\"binary_crossentropy\", metrics=['acc'], optimizer=Adam(0.0001))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    plot_model(model, to_file='model_plot.png',\n",
    "               show_shapes=True, show_layer_names=True)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " vggface_resnet50 (Functional)  (None, None, None,   23561152    ['input_1[0][0]',                \n",
      "                                2048)                             'input_2[0][0]',                \n",
      "                                                                  'input_3[0][0]']                \n",
      "                                                                                                  \n",
      " global_max_pooling2d (GlobalMa  (None, 2048)        0           ['vggface_resnet50[0][0]']       \n",
      " xPooling2D)                                                                                      \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 2048)        0           ['vggface_resnet50[0][0]']       \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " global_max_pooling2d_2 (Global  (None, 2048)        0           ['vggface_resnet50[2][0]']       \n",
      " MaxPooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " global_average_pooling2d_2 (Gl  (None, 2048)        0           ['vggface_resnet50[2][0]']       \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " global_max_pooling2d_1 (Global  (None, 2048)        0           ['vggface_resnet50[1][0]']       \n",
      " MaxPooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " global_average_pooling2d_1 (Gl  (None, 2048)        0           ['vggface_resnet50[1][0]']       \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 4096)         0           ['global_max_pooling2d[0][0]',   \n",
      "                                                                  'global_average_pooling2d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 4096)         0           ['global_max_pooling2d_2[0][0]', \n",
      "                                                                  'global_average_pooling2d_2[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 4096)         0           ['global_max_pooling2d_1[0][0]', \n",
      "                                                                  'global_average_pooling2d_1[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " subtract (Subtract)            (None, 4096)         0           ['concatenate[0][0]',            \n",
      "                                                                  'concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " subtract_1 (Subtract)          (None, 4096)         0           ['concatenate_1[0][0]',          \n",
      "                                                                  'concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " multiply_2 (Multiply)          (None, 4096)         0           ['concatenate[0][0]',            \n",
      "                                                                  'concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " multiply (Multiply)            (None, 4096)         0           ['subtract[0][0]',               \n",
      "                                                                  'subtract[0][0]']               \n",
      "                                                                                                  \n",
      " multiply_3 (Multiply)          (None, 4096)         0           ['concatenate_1[0][0]',          \n",
      "                                                                  'concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " multiply_1 (Multiply)          (None, 4096)         0           ['subtract_1[0][0]',             \n",
      "                                                                  'subtract_1[0][0]']             \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 8192)         0           ['multiply_2[0][0]',             \n",
      "                                                                  'multiply[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 8192)         0           ['multiply_3[0][0]',             \n",
      "                                                                  'multiply_1[0][0]']             \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 16384)        0           ['concatenate_3[0][0]',          \n",
      "                                                                  'concatenate_4[0][0]']          \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 100)          1638500     ['concatenate_5[0][0]']          \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 100)          0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1)            101         ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 25,199,753\n",
      "Trainable params: 25,146,633\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/30\n",
      "50/50 [==============================] - ETA: 0s - loss: 1.7822 - acc: 0.5250 \n",
      "Epoch 1: acc improved from -inf to 0.52500, saving model to vgg_face.h5\n",
      "50/50 [==============================] - 961s 19s/step - loss: 1.7822 - acc: 0.5250 - val_loss: 0.9233 - val_acc: 0.5688 - lr: 1.0000e-04\n",
      "Epoch 2/30\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.6558 - acc: 0.6363 \n",
      "Epoch 2: acc improved from 0.52500 to 0.63625, saving model to vgg_face.h5\n",
      "50/50 [==============================] - 899s 18s/step - loss: 0.6558 - acc: 0.6363 - val_loss: 0.7416 - val_acc: 0.6625 - lr: 1.0000e-04\n",
      "Epoch 3/30\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.5991 - acc: 0.6587 \n",
      "Epoch 3: acc improved from 0.63625 to 0.65875, saving model to vgg_face.h5\n",
      "50/50 [==============================] - 901s 18s/step - loss: 0.5991 - acc: 0.6587 - val_loss: 0.6994 - val_acc: 0.5938 - lr: 1.0000e-04\n",
      "Epoch 4/30\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.5601 - acc: 0.6975 \n",
      "Epoch 4: acc improved from 0.65875 to 0.69750, saving model to vgg_face.h5\n",
      "50/50 [==============================] - 888s 18s/step - loss: 0.5601 - acc: 0.6975 - val_loss: 0.6648 - val_acc: 0.6250 - lr: 1.0000e-04\n",
      "Epoch 5/30\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.5436 - acc: 0.7113 \n",
      "Epoch 5: acc improved from 0.69750 to 0.71125, saving model to vgg_face.h5\n",
      "50/50 [==============================] - 897s 18s/step - loss: 0.5436 - acc: 0.7113 - val_loss: 0.5481 - val_acc: 0.6812 - lr: 1.0000e-04\n",
      "Epoch 6/30\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.4955 - acc: 0.7613 \n",
      "Epoch 6: acc improved from 0.71125 to 0.76125, saving model to vgg_face.h5\n",
      "50/50 [==============================] - 882s 18s/step - loss: 0.4955 - acc: 0.7613 - val_loss: 0.5585 - val_acc: 0.7437 - lr: 1.0000e-04\n",
      "Epoch 7/30\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.4943 - acc: 0.7425 \n",
      "Epoch 7: acc did not improve from 0.76125\n",
      "50/50 [==============================] - 885s 18s/step - loss: 0.4943 - acc: 0.7425 - val_loss: 0.6861 - val_acc: 0.6625 - lr: 1.0000e-04\n",
      "Epoch 8/30\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.4958 - acc: 0.7437 \n",
      "Epoch 8: acc did not improve from 0.76125\n",
      "50/50 [==============================] - 880s 18s/step - loss: 0.4958 - acc: 0.7437 - val_loss: 0.5315 - val_acc: 0.7563 - lr: 1.0000e-04\n",
      "Epoch 9/30\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.5056 - acc: 0.7475 \n",
      "Epoch 9: acc did not improve from 0.76125\n",
      "50/50 [==============================] - 865s 17s/step - loss: 0.5056 - acc: 0.7475 - val_loss: 0.5545 - val_acc: 0.6875 - lr: 1.0000e-04\n",
      "Epoch 10/30\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.4874 - acc: 0.7588 \n",
      "Epoch 10: acc did not improve from 0.76125\n",
      "50/50 [==============================] - 866s 17s/step - loss: 0.4874 - acc: 0.7588 - val_loss: 0.6107 - val_acc: 0.6812 - lr: 1.0000e-04\n",
      "Epoch 11/30\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.4736 - acc: 0.7763 \n",
      "Epoch 11: acc improved from 0.76125 to 0.77625, saving model to vgg_face.h5\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "50/50 [==============================] - 869s 17s/step - loss: 0.4736 - acc: 0.7763 - val_loss: 0.5827 - val_acc: 0.7188 - lr: 1.0000e-04\n",
      "Epoch 12/30\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.4721 - acc: 0.7812 \n",
      "Epoch 12: acc improved from 0.77625 to 0.78125, saving model to vgg_face.h5\n",
      "50/50 [==============================] - 869s 17s/step - loss: 0.4721 - acc: 0.7812 - val_loss: 0.5985 - val_acc: 0.6750 - lr: 1.0000e-05\n",
      "Epoch 13/30\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.4318 - acc: 0.8050 \n",
      "Epoch 13: acc improved from 0.78125 to 0.80500, saving model to vgg_face.h5\n",
      "50/50 [==============================] - 868s 17s/step - loss: 0.4318 - acc: 0.8050 - val_loss: 0.6137 - val_acc: 0.6625 - lr: 1.0000e-05\n",
      "Epoch 14/30\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.4140 - acc: 0.8238 \n",
      "Epoch 14: acc improved from 0.80500 to 0.82375, saving model to vgg_face.h5\n",
      "\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "50/50 [==============================] - 884s 18s/step - loss: 0.4140 - acc: 0.8238 - val_loss: 0.6201 - val_acc: 0.6687 - lr: 1.0000e-05\n",
      "Epoch 15/30\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.4042 - acc: 0.8188 \n",
      "Epoch 15: acc did not improve from 0.82375\n",
      "50/50 [==============================] - 872s 17s/step - loss: 0.4042 - acc: 0.8188 - val_loss: 0.6156 - val_acc: 0.6812 - lr: 1.0000e-06\n",
      "Epoch 16/30\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.3991 - acc: 0.8037 \n",
      "Epoch 16: acc did not improve from 0.82375\n",
      "50/50 [==============================] - 846s 17s/step - loss: 0.3991 - acc: 0.8037 - val_loss: 0.5779 - val_acc: 0.7125 - lr: 1.0000e-06\n",
      "Epoch 17/30\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.3845 - acc: 0.8175 \n",
      "Epoch 17: acc did not improve from 0.82375\n",
      "\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
      "50/50 [==============================] - 844s 17s/step - loss: 0.3845 - acc: 0.8175 - val_loss: 0.5945 - val_acc: 0.7125 - lr: 1.0000e-06\n",
      "Epoch 18/30\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.4120 - acc: 0.8087 \n",
      "Epoch 18: acc did not improve from 0.82375\n",
      "50/50 [==============================] - 841s 17s/step - loss: 0.4120 - acc: 0.8087 - val_loss: 0.7191 - val_acc: 0.6562 - lr: 1.0000e-07\n",
      "Epoch 19/30\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.3873 - acc: 0.8163 \n",
      "Epoch 19: acc did not improve from 0.82375\n",
      "50/50 [==============================] - 839s 17s/step - loss: 0.3873 - acc: 0.8163 - val_loss: 0.7187 - val_acc: 0.6625 - lr: 1.0000e-07\n",
      "Epoch 20/30\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.4314 - acc: 0.7962 \n",
      "Epoch 20: acc did not improve from 0.82375\n",
      "\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 1.0000000116860975e-08.\n",
      "50/50 [==============================] - 845s 17s/step - loss: 0.4314 - acc: 0.7962 - val_loss: 0.5704 - val_acc: 0.7312 - lr: 1.0000e-07\n",
      "Epoch 21/30\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.4144 - acc: 0.7912 \n",
      "Epoch 21: acc did not improve from 0.82375\n",
      "50/50 [==============================] - 839s 17s/step - loss: 0.4144 - acc: 0.7912 - val_loss: 0.5755 - val_acc: 0.6625 - lr: 1.0000e-08\n",
      "Epoch 22/30\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.4013 - acc: 0.7962 \n",
      "Epoch 22: acc did not improve from 0.82375\n",
      "50/50 [==============================] - 853s 17s/step - loss: 0.4013 - acc: 0.7962 - val_loss: 0.6250 - val_acc: 0.6313 - lr: 1.0000e-08\n",
      "Epoch 23/30\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.4141 - acc: 0.7937 \n",
      "Epoch 23: acc did not improve from 0.82375\n",
      "\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 9.999999939225292e-10.\n",
      "50/50 [==============================] - 836s 17s/step - loss: 0.4141 - acc: 0.7937 - val_loss: 0.6026 - val_acc: 0.6562 - lr: 1.0000e-08\n",
      "Epoch 24/30\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.3992 - acc: 0.8225 \n",
      "Epoch 24: acc did not improve from 0.82375\n",
      "50/50 [==============================] - 841s 17s/step - loss: 0.3992 - acc: 0.8225 - val_loss: 0.6763 - val_acc: 0.6438 - lr: 1.0000e-09\n",
      "Epoch 25/30\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.4096 - acc: 0.7925 \n",
      "Epoch 25: acc did not improve from 0.82375\n",
      "50/50 [==============================] - 837s 17s/step - loss: 0.4096 - acc: 0.7925 - val_loss: 0.5072 - val_acc: 0.7250 - lr: 1.0000e-09\n",
      "Epoch 26/30\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.4240 - acc: 0.7987 \n",
      "Epoch 26: acc did not improve from 0.82375\n",
      "\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 9.999999717180686e-11.\n",
      "50/50 [==============================] - 839s 17s/step - loss: 0.4240 - acc: 0.7987 - val_loss: 0.7011 - val_acc: 0.6500 - lr: 1.0000e-09\n",
      "Epoch 27/30\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.4033 - acc: 0.7962 \n",
      "Epoch 27: acc did not improve from 0.82375\n",
      "50/50 [==============================] - 838s 17s/step - loss: 0.4033 - acc: 0.7962 - val_loss: 0.5822 - val_acc: 0.7188 - lr: 1.0000e-10\n",
      "Epoch 28/30\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.3717 - acc: 0.8213 \n",
      "Epoch 28: acc did not improve from 0.82375\n",
      "50/50 [==============================] - 837s 17s/step - loss: 0.3717 - acc: 0.8213 - val_loss: 0.5566 - val_acc: 0.7063 - lr: 1.0000e-10\n",
      "Epoch 29/30\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.3980 - acc: 0.8200 \n",
      "Epoch 29: acc did not improve from 0.82375\n",
      "\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 9.99999943962493e-12.\n",
      "50/50 [==============================] - 836s 17s/step - loss: 0.3980 - acc: 0.8200 - val_loss: 0.5892 - val_acc: 0.6750 - lr: 1.0000e-10\n",
      "Epoch 30/30\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.3980 - acc: 0.8075 \n",
      "Epoch 30: acc did not improve from 0.82375\n",
      "50/50 [==============================] - 833s 17s/step - loss: 0.3980 - acc: 0.8075 - val_loss: 0.5867 - val_acc: 0.7000 - lr: 1.0000e-11\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x237ae5fe8b0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = \"vgg_face.h5\"\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    file_path, monitor='acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "reduce_on_plateau = ReduceLROnPlateau(\n",
    "    monitor=\"val_acc\", mode=\"max\", factor=0.1, patience=3, verbose=1)\n",
    "\n",
    "callbacks_list = [checkpoint, reduce_on_plateau]\n",
    "\n",
    "model = baseline_model()\n",
    "# model.load_weights(file_path)\n",
    "model.fit(gen(triplet_family_comb, map_train_individual_to_images, Fathers_train, Mothers_train, Children_train, batch_size=16),\n",
    "          validation_data=gen_val(triplet_val, validation_labels, batch_size=16), epochs=30, verbose=1,\n",
    "          callbacks=callbacks_list, steps_per_epoch=50, validation_steps=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
